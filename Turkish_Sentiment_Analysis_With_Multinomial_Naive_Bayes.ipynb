{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish Sentiment Analysis With Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: import required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: import  Verius NLP tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from veriusapigateway import VeriUsAPIGateway\n",
    "vu = VeriUsAPIGateway(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./sample_beyazperde_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: drop the \"NAN\" values from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5:  drop \"Neutral\" labeled data if there exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.target !=\"Neutral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6:  load Turkish stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stopwords.txt\", \"r\") as sw:\n",
    "        stops = [s.strip() for s in sw.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7:  inspect the size of the \"Positive\" and \"Negative\" labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1</td>\n",
       "      <td>3138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          target  text\n",
       "target                \n",
       "Negative       1   637\n",
       "Positive       1  3138"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"target\").nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8:  to avoid overfitting, take equal size of samples from both classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1274"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  take 637 samples each of classes\n",
    "df_pos = df[df.target ==\"Positive\"].head(637)\n",
    "df_neg = df[df.target ==\"Negative\"].head(637)\n",
    "df_equ = df_pos.append(df_neg)\n",
    "len(df_equ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9:  shuffle the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Saçma film,biraz tuhaf bir kovalamaca birazda ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Mükemmel ötesi bir film.Hele o tankeri patlatm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Ben hayatımda böyle bir film izlemedim. Şahane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Helen Mirren'in Oyunculuğu Kötü... Bir İletişi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>Negative</td>\n",
       "      <td>oyuncular çok iyi ama bence bukadarda abartmay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                               text\n",
       "3542  Negative  Saçma film,biraz tuhaf bir kovalamaca birazda ...\n",
       "582   Positive  Mükemmel ötesi bir film.Hele o tankeri patlatm...\n",
       "1433  Negative  Ben hayatımda böyle bir film izlemedim. Şahane...\n",
       "2017  Negative  Helen Mirren'in Oyunculuğu Kötü... Bir İletişi...\n",
       "3390  Negative  oyuncular çok iyi ama bence bukadarda abartmay..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df_equ)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10:  drop stopwords, punctuations and lower the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_stopwords(raw_text):\n",
    "    clean_data = [] \n",
    "    for text in raw_text:\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "\n",
    "\n",
    "        stop_words = set(stops)\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "        clean_data.append(\" \".join([w for w in words]))\n",
    "    \n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>stopwords_dropped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Saçma film,biraz tuhaf bir kovalamaca birazda ...</td>\n",
       "      <td>saçma film tuhaf kovalamaca birazda değişik ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Mükemmel ötesi bir film.Hele o tankeri patlatm...</td>\n",
       "      <td>mükemmel ötesi filmhele tankeri patlatma sahne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Ben hayatımda böyle bir film izlemedim. Şahane...</td>\n",
       "      <td>hayatımda film izlemedim şahane derece gerçekl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Helen Mirren'in Oyunculuğu Kötü... Bir İletişi...</td>\n",
       "      <td>helen mirrenin oyunculuğu kötü fakültesi sinem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>Negative</td>\n",
       "      <td>oyuncular çok iyi ama bence bukadarda abartmay...</td>\n",
       "      <td>oyuncular iyi bence bukadarda abartmayın aman ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                               text  \\\n",
       "3542  Negative  Saçma film,biraz tuhaf bir kovalamaca birazda ...   \n",
       "582   Positive  Mükemmel ötesi bir film.Hele o tankeri patlatm...   \n",
       "1433  Negative  Ben hayatımda böyle bir film izlemedim. Şahane...   \n",
       "2017  Negative  Helen Mirren'in Oyunculuğu Kötü... Bir İletişi...   \n",
       "3390  Negative  oyuncular çok iyi ama bence bukadarda abartmay...   \n",
       "\n",
       "                                      stopwords_dropped  \n",
       "3542  saçma film tuhaf kovalamaca birazda değişik ka...  \n",
       "582   mükemmel ötesi filmhele tankeri patlatma sahne...  \n",
       "1433  hayatımda film izlemedim şahane derece gerçekl...  \n",
       "2017  helen mirrenin oyunculuğu kötü fakültesi sinem...  \n",
       "3390  oyuncular iyi bence bukadarda abartmayın aman ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## to avoid SettingWithCopyWarning, copy the original df as dfa and return the df\n",
    "dfa = df.copy()\n",
    "dfa[\"stopwords_dropped\"] = drop_stopwords(dfa.text)\n",
    "df = dfa.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11:  normalize each sentence in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(stopwords_dropped_text):\n",
    "    normalized = []\n",
    "    for sentence in stopwords_dropped_text:\n",
    "        normalized.append(vu.get_normal(sentence))\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>stopwords_dropped</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Saçma film,biraz tuhaf bir kovalamaca birazda ...</td>\n",
       "      <td>saçma film tuhaf kovalamaca birazda değişik ka...</td>\n",
       "      <td>saçma film tuhaf kovalamaca birazda değişik ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Mükemmel ötesi bir film.Hele o tankeri patlatm...</td>\n",
       "      <td>mükemmel ötesi filmhele tankeri patlatma sahne...</td>\n",
       "      <td>mükemmel ötesi filmsele tankeri patlatma sahne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Ben hayatımda böyle bir film izlemedim. Şahane...</td>\n",
       "      <td>hayatımda film izlemedim şahane derece gerçekl...</td>\n",
       "      <td>hayatımda film izlemedim şahane derece gerçekl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Helen Mirren'in Oyunculuğu Kötü... Bir İletişi...</td>\n",
       "      <td>helen mirrenin oyunculuğu kötü fakültesi sinem...</td>\n",
       "      <td>helen midenin oyunculuğu kötü fakültesi sinema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>Negative</td>\n",
       "      <td>oyuncular çok iyi ama bence bukadarda abartmay...</td>\n",
       "      <td>oyuncular iyi bence bukadarda abartmayın aman ...</td>\n",
       "      <td>oyuncular iyi bence Buka'larda abartmayın aman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                               text  \\\n",
       "3542  Negative  Saçma film,biraz tuhaf bir kovalamaca birazda ...   \n",
       "582   Positive  Mükemmel ötesi bir film.Hele o tankeri patlatm...   \n",
       "1433  Negative  Ben hayatımda böyle bir film izlemedim. Şahane...   \n",
       "2017  Negative  Helen Mirren'in Oyunculuğu Kötü... Bir İletişi...   \n",
       "3390  Negative  oyuncular çok iyi ama bence bukadarda abartmay...   \n",
       "\n",
       "                                      stopwords_dropped  \\\n",
       "3542  saçma film tuhaf kovalamaca birazda değişik ka...   \n",
       "582   mükemmel ötesi filmhele tankeri patlatma sahne...   \n",
       "1433  hayatımda film izlemedim şahane derece gerçekl...   \n",
       "2017  helen mirrenin oyunculuğu kötü fakültesi sinem...   \n",
       "3390  oyuncular iyi bence bukadarda abartmayın aman ...   \n",
       "\n",
       "                                             normalized  \n",
       "3542  saçma film tuhaf kovalamaca birazda değişik ka...  \n",
       "582   mükemmel ötesi filmsele tankeri patlatma sahne...  \n",
       "1433  hayatımda film izlemedim şahane derece gerçekl...  \n",
       "2017  helen midenin oyunculuğu kötü fakültesi sinema...  \n",
       "3390  oyuncular iyi bence Buka'larda abartmayın aman...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"normalized\"] = normalizer(df.stopwords_dropped)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12:  stem each sentence tokens in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(normalized_text):\n",
    "    stemmed = []\n",
    "    for sentence in normalized_text:\n",
    "        stemmed.append(vu.get_stem(sentence))\n",
    "    \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>stopwords_dropped</th>\n",
       "      <th>normalized</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Saçma film,biraz tuhaf bir kovalamaca birazda ...</td>\n",
       "      <td>saçma film tuhaf kovalamaca birazda değişik ka...</td>\n",
       "      <td>saçma film tuhaf kovalamaca birazda değişik ka...</td>\n",
       "      <td>saçm film tuhaf kovalama biraz değişik karakte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Mükemmel ötesi bir film.Hele o tankeri patlatm...</td>\n",
       "      <td>mükemmel ötesi filmhele tankeri patlatma sahne...</td>\n",
       "      <td>mükemmel ötesi filmsele tankeri patlatma sahne...</td>\n",
       "      <td>mükemmel öte filmse tanker patla sahne gül kar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Ben hayatımda böyle bir film izlemedim. Şahane...</td>\n",
       "      <td>hayatımda film izlemedim şahane derece gerçekl...</td>\n",
       "      <td>hayatımda film izlemedim şahane derece gerçekl...</td>\n",
       "      <td>hayat film izle şahane derec gerçek uzak senar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Helen Mirren'in Oyunculuğu Kötü... Bir İletişi...</td>\n",
       "      <td>helen mirrenin oyunculuğu kötü fakültesi sinem...</td>\n",
       "      <td>helen midenin oyunculuğu kötü fakültesi sinema...</td>\n",
       "      <td>he mide oyun kötü fakülte sine bölüm mezun osc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>Negative</td>\n",
       "      <td>oyuncular çok iyi ama bence bukadarda abartmay...</td>\n",
       "      <td>oyuncular iyi bence bukadarda abartmayın aman ...</td>\n",
       "      <td>oyuncular iyi bence Buka'larda abartmayın aman...</td>\n",
       "      <td>oyun iyi ben Buka lar abart aman aman bir film...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                               text  \\\n",
       "3542  Negative  Saçma film,biraz tuhaf bir kovalamaca birazda ...   \n",
       "582   Positive  Mükemmel ötesi bir film.Hele o tankeri patlatm...   \n",
       "1433  Negative  Ben hayatımda böyle bir film izlemedim. Şahane...   \n",
       "2017  Negative  Helen Mirren'in Oyunculuğu Kötü... Bir İletişi...   \n",
       "3390  Negative  oyuncular çok iyi ama bence bukadarda abartmay...   \n",
       "\n",
       "                                      stopwords_dropped  \\\n",
       "3542  saçma film tuhaf kovalamaca birazda değişik ka...   \n",
       "582   mükemmel ötesi filmhele tankeri patlatma sahne...   \n",
       "1433  hayatımda film izlemedim şahane derece gerçekl...   \n",
       "2017  helen mirrenin oyunculuğu kötü fakültesi sinem...   \n",
       "3390  oyuncular iyi bence bukadarda abartmayın aman ...   \n",
       "\n",
       "                                             normalized  \\\n",
       "3542  saçma film tuhaf kovalamaca birazda değişik ka...   \n",
       "582   mükemmel ötesi filmsele tankeri patlatma sahne...   \n",
       "1433  hayatımda film izlemedim şahane derece gerçekl...   \n",
       "2017  helen midenin oyunculuğu kötü fakültesi sinema...   \n",
       "3390  oyuncular iyi bence Buka'larda abartmayın aman...   \n",
       "\n",
       "                                                stemmed  \n",
       "3542  saçm film tuhaf kovalama biraz değişik karakte...  \n",
       "582   mükemmel öte filmse tanker patla sahne gül kar...  \n",
       "1433  hayat film izle şahane derec gerçek uzak senar...  \n",
       "2017  he mide oyun kötü fakülte sine bölüm mezun osc...  \n",
       "3390  oyun iyi ben Buka lar abart aman aman bir film...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"stemmed\"] = stemmer(df.normalized)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 13:  drop unnecessary columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>Negative</td>\n",
       "      <td>saçm film tuhaf kovalama biraz değişik karakte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Positive</td>\n",
       "      <td>mükemmel öte filmse tanker patla sahne gül kar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>Negative</td>\n",
       "      <td>hayat film izle şahane derec gerçek uzak senar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>Negative</td>\n",
       "      <td>he mide oyun kötü fakülte sine bölüm mezun osc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>Negative</td>\n",
       "      <td>oyun iyi ben Buka lar abart aman aman bir film...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target                                            stemmed\n",
       "3542  Negative  saçm film tuhaf kovalama biraz değişik karakte...\n",
       "582   Positive  mükemmel öte filmse tanker patla sahne gül kar...\n",
       "1433  Negative  hayat film izle şahane derec gerçek uzak senar...\n",
       "2017  Negative  he mide oyun kötü fakülte sine bölüm mezun osc...\n",
       "3390  Negative  oyun iyi ben Buka lar abart aman aman bir film..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['text', 'stopwords_dropped', 'normalized'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 14:  split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.stemmed, df.target, test_size=0.20, random_state = 42)\n",
    "## shape of the training data\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 15:  vectorize the dataset using \"TfidfVectorizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019, 21496)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stops, ngram_range=(1, 2))\n",
    "vectorizer.fit(X_train)\n",
    "#  get the trainig and test features by transforming vectorizer\n",
    "training_features = vectorizer.transform(X_train)    \n",
    "test_features = vectorizer.transform(X_test)\n",
    "## shape of the vectorized training data\n",
    "training_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 16:  apply \"GridSearchCV\" method for \"MultinomialNB\" classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  create an instance of \"MultinomialNB\" classifier \n",
    "mnb = MultinomialNB()\n",
    "# give some tuned_parameters in order to find the best alpha hyperparameter\n",
    "tuned_parameters = {\n",
    "    'alpha': [1, 1e-1, 1e-2]\n",
    "}\n",
    "# create a scorer to compare the parameters\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "# create an instance of \"GridSearchCV\" class and give parameters\n",
    "grid_obj = GridSearchCV(mnb, tuned_parameters, cv=10, scoring=acc_scorer)\n",
    "grid_obj = grid_obj.fit(training_features, y_train)\n",
    "# set the model to the best combination of parameters\n",
    "model = grid_obj.best_estimator_\n",
    "# fit the best model for the dataset \n",
    "model.fit(training_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 17:  predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_features)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 18:  observe the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score on the dataset:0.82\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_score on the dataset:{:.2f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 19:  create a classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.81      0.84      0.83       132\n",
      "    Positive       0.82      0.79      0.80       123\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       255\n",
      "   macro avg       0.82      0.81      0.82       255\n",
      "weighted avg       0.82      0.82      0.82       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = df.target.unique()\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 20:  observe the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111,  21],\n",
       "       [ 26,  97]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 21:  observe the prediction probabilities of the wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_ratio</th>\n",
       "      <th>pos_ratio</th>\n",
       "      <th>pred</th>\n",
       "      <th>real</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>0.496332</td>\n",
       "      <td>0.503668</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>biçi bir fil ya adam sade izle dış film bir yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>0.392982</td>\n",
       "      <td>0.607018</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>karanlık film sev sil hoşlan film gerek kasvet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.529298</td>\n",
       "      <td>0.470702</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>salon sade kere gül se gel diy arkadaş fark fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.452754</td>\n",
       "      <td>0.547246</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>garip fil ol katil kon cinayet roman eda karma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.342994</td>\n",
       "      <td>0.657006</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>kon güzel film benze başla film anlatım berbat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_ratio  pos_ratio      pred      real  \\\n",
       "4015   0.496332   0.503668  Positive  Negative   \n",
       "989    0.392982   0.607018  Positive  Negative   \n",
       "212    0.529298   0.470702  Negative  Positive   \n",
       "172    0.452754   0.547246  Positive  Negative   \n",
       "687    0.342994   0.657006  Positive  Negative   \n",
       "\n",
       "                                                stemmed  \n",
       "4015  biçi bir fil ya adam sade izle dış film bir yo...  \n",
       "989   karanlık film sev sil hoşlan film gerek kasvet...  \n",
       "212   salon sade kere gül se gel diy arkadaş fark fi...  \n",
       "172   garip fil ol katil kon cinayet roman eda karma...  \n",
       "687   kon güzel film benze başla film anlatım berbat...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob = model.predict_proba(test_features)\n",
    "data = {'neg_ratio': pred_prob[:,0], 'pos_ratio': pred_prob[:,1],'pred': y_pred, 'real': y_test,'stemmed': X_test}\n",
    "df_pred_prob = pd.DataFrame(data=data)\n",
    "df_pred_prob = df_pred_prob[df_pred_prob.pred != df_pred_prob.real]\n",
    "df_pred_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 22:  apply ten-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro:0.83\n",
      "precision_macro:0.83\n",
      "recall_macro:0.83\n",
      "accuracy:0.83\n"
     ]
    }
   ],
   "source": [
    "#  convert targets to numbers since cross_validate works with numbers\n",
    "df[\"target_binary\"] = df.target.replace(\"Positive\",1).replace(\"Negative\",0)\n",
    "scoring_list = [\"f1_macro\",\"precision_macro\",\"recall_macro\",\"accuracy\"]\n",
    "scores = cross_validate(model,vectorizer.transform(df.stemmed), df.target_binary, cv=10, scoring=scoring_list)\n",
    "for scr in scoring_list:\n",
    "    print(scr+\":\"+\"{:.2f}\".format(scores[\"test_\"+scr].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 23:  create pipeline for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('clf', model),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 24:  pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model,'Turkish_Sentiment_Analysis_With_Multinomial_Naive_Bayes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
